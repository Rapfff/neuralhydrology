{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add the parent folder to the sys.path\n",
    "sys.path.append('../..')  # Add the parent of the parent folder to the sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\reynoura\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from neuralhydrology.nh_run import start_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:15:00,704: Logging to runs\\dev\\run_0502_111500\\output.log initialized.\n",
      "2024-02-05 11:15:00,705: ### Folder structure created at runs\\dev\\run_0502_111500\n",
      "2024-02-05 11:15:00,705: ### Run configurations for run\n",
      "2024-02-05 11:15:00,706: experiment_name: None\n",
      "2024-02-05 11:15:00,707: run_dir: runs\\dev\\run_0502_111500\n",
      "2024-02-05 11:15:00,708: train_basin_file: 2_basin_list.txt\n",
      "2024-02-05 11:15:00,709: validation_basin_file: 2_basin_list.txt\n",
      "2024-02-05 11:15:00,710: test_basin_file: 2_basin_list.txt\n",
      "2024-02-05 11:15:00,711: train_start_date: 2006-10-01 00:00:00\n",
      "2024-02-05 11:15:00,712: train_end_date: 2008-09-30 00:00:00\n",
      "2024-02-05 11:15:00,713: validation_start_date: 2002-10-01 00:00:00\n",
      "2024-02-05 11:15:00,713: validation_end_date: 2004-09-30 00:00:00\n",
      "2024-02-05 11:15:00,715: test_start_date: 1998-10-01 00:00:00\n",
      "2024-02-05 11:15:00,715: test_end_date: 2000-09-30 00:00:00\n",
      "2024-02-05 11:15:00,715: per_basin_train_periods_file: None\n",
      "2024-02-05 11:15:00,717: per_basin_validation_periods_file: None\n",
      "2024-02-05 11:15:00,718: per_basin_test_periods_file: None\n",
      "2024-02-05 11:15:00,719: seed: None\n",
      "2024-02-05 11:15:00,720: device: cpu\n",
      "2024-02-05 11:15:00,720: validate_every: 10\n",
      "2024-02-05 11:15:00,721: validate_n_random_basins: -1\n",
      "2024-02-05 11:15:00,722: cache_validation_data: True\n",
      "2024-02-05 11:15:00,723: metrics: ['NSE', 'KGE', 'Alpha-NSE', 'Beta-NSE']\n",
      "2024-02-05 11:15:00,723: model: superflex\n",
      "2024-02-05 11:15:00,724: model_description: fabrizio.txt\n",
      "2024-02-05 11:15:00,725: checkpoint_path: None\n",
      "2024-02-05 11:15:00,726: head: regression\n",
      "2024-02-05 11:15:00,727: output_activation: linear\n",
      "2024-02-05 11:15:00,728: statics_embedding: {'type': 'fc', 'hiddens': [20], 'activation': 'tanh', 'dropout': 0.0}\n",
      "2024-02-05 11:15:00,728: mass_inputs: ['prcp(mm/day)']\n",
      "2024-02-05 11:15:00,728: custom_normalization: {'prcp(mm/day)': {'centering': 'None', 'scaling': 'None'}, 'QObs(mm/d)': {'centering': 'None', 'scaling': 'None'}}\n",
      "2024-02-05 11:15:00,731: optimizer: Adam\n",
      "2024-02-05 11:15:00,731: loss: NSE\n",
      "2024-02-05 11:15:00,734: regularization: None\n",
      "2024-02-05 11:15:00,735: learning_rate: {0: 0.001, 10: 0.0005, 25: 0.0001}\n",
      "2024-02-05 11:15:00,736: batch_size: 32\n",
      "2024-02-05 11:15:00,736: epochs: 50\n",
      "2024-02-05 11:15:00,736: target_noise_std: 0.005\n",
      "2024-02-05 11:15:00,736: clip_gradient_norm: 1\n",
      "2024-02-05 11:15:00,736: predict_last_n: 1\n",
      "2024-02-05 11:15:00,736: seq_length: 365\n",
      "2024-02-05 11:15:00,736: num_workers: 1\n",
      "2024-02-05 11:15:00,736: log_interval: 1\n",
      "2024-02-05 11:15:00,736: log_tensorboard: True\n",
      "2024-02-05 11:15:00,736: log_n_figures: -1\n",
      "2024-02-05 11:15:00,736: save_weights_every: 1\n",
      "2024-02-05 11:15:00,736: save_validation_results: True\n",
      "2024-02-05 11:15:00,736: dataset: camels_us\n",
      "2024-02-05 11:15:00,736: data_dir: ..\\..\\data\\fake\n",
      "2024-02-05 11:15:00,736: save_train_data: False\n",
      "2024-02-05 11:15:00,736: train_data_file: None\n",
      "2024-02-05 11:15:00,750: forcings: ['daymet']\n",
      "2024-02-05 11:15:00,751: dynamic_inputs: ['prcp(mm/day)']\n",
      "2024-02-05 11:15:00,752: target_variables: ['QObs(mm/d)']\n",
      "2024-02-05 11:15:00,752: clip_targets_to_zero: ['QObs(mm/d)']\n",
      "2024-02-05 11:15:00,753: static_attributes: ['elev_mean', 'slope_mean']\n",
      "2024-02-05 11:15:00,753: additional_feature_files: None\n",
      "2024-02-05 11:15:00,754: evolving_attributes: None\n",
      "2024-02-05 11:15:00,754: use_basin_id_encoding: False\n",
      "2024-02-05 11:15:00,755: number_of_basins: 2\n",
      "2024-02-05 11:15:00,755: train_dir: runs\\dev\\run_0502_111500\\train_data\n",
      "2024-02-05 11:15:00,756: img_log_dir: runs\\dev\\run_0502_111500\\img_log\n",
      "2024-02-05 11:15:00,758: ### Device cpu will be used for training\n",
      "2024-02-05 11:15:00,790: Loading basin data into xarray data set.\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.98it/s]\n",
      "2024-02-05 11:15:00,969: Calculating target variable stds per basin\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "2024-02-05 11:15:00,988: Create lookup table and convert to pytorch tensor\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65it/s]"
     ]
    }
   ],
   "source": [
    "start_run(config_file=Path(\"fabrizio.yml\", gpu=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = \"../../runs/dev/run_size_1\"\n",
    "#eval_run(run_dir=run_dir, period=\"test\")\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "qsim = []\n",
    "for i in range(10,51,10):\n",
    "    with open(run_dir + \"/validation/model_epoch0\"+str(i)+\"/validation_results.p\", \"rb\") as fp:\n",
    "        results = pickle.load(fp)\n",
    "        qsim.append(results['01510000']['1D']['xr']['QObs(mm/d)_sim'])\n",
    "        if i == 10:\n",
    "            qobs = results['01510000']['1D']['xr']['QObs(mm/d)_obs']\n",
    "\n",
    "plt.plot(qobs, label='observed')\n",
    "for i in range(1,6,2):\n",
    "    plt.plot(qsim[i-1],label=\"epoch \"+str(i*10), alpha = 0.15*i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralhydrology.evaluation import metrics\n",
    "\n",
    "models = {}\n",
    "for j in [1,4,10]:\n",
    "    metric_values = []\n",
    "    run_dir = \"../../runs/dev/run_size_\"+str(j)\n",
    "    qsim = []\n",
    "    for i in range(10,51,10):\n",
    "        with open(run_dir + \"/validation/model_epoch0\"+str(i)+\"/validation_results.p\", \"rb\") as fp:\n",
    "            results = pickle.load(fp)\n",
    "            qsim.append(results['01510000']['1D']['xr']['QObs(mm/d)_sim'])\n",
    "\n",
    "    for i in range(1,6):\n",
    "        metric_values.append(metrics.calculate_all_metrics(qobs.isel(time_step=-1),\n",
    "                                                        qsim[i-1].isel(time_step=-1)))\n",
    "    \n",
    "    models[j] = metric_values\n",
    "\n",
    "fig, axs = plt.subplots(3, 1+len(metric_values[0])//3, sharex=True)\n",
    "colors = [None,'r',None,None,'g',None,None,None,None,None,'b']\n",
    "for j in [1,4,10]:\n",
    "    metric_values = models[j]\n",
    "    for ik, k in enumerate(list(metric_values[0].keys())):\n",
    "        y = [i[k] for i in metric_values]\n",
    "        axs[ik%3][ik//3].plot(list(range(10,51,10)),y,c = colors[j],label=str(j)+' routing reservoirs')\n",
    "        if j == 10:\n",
    "            axs[ik%3][ik//3].set_title(k)\n",
    "            axs[ik%3][ik//3].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
